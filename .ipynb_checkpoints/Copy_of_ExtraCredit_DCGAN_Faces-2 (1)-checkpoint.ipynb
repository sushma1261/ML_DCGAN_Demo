{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qdxsjoXsfIw"
   },
   "source": [
    "Extra Credit Assignment :  Complete this Notebook to implement a DCGAN similar to what is described in the paper \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\" by Radford et al. (2016).https://arxiv.org/abs/1511.06434v2  \n",
    "\n",
    "General guidelines\n",
    "1. MAKE A COPY OF THIS NOTEBOOK TEMPLATE TO YOUR OWN DRIVE BEFORE REVISING. You can download your version of the notebook and submit it to CANVAS as a .ipynb notebook file\n",
    "2. You will be using a celebrity faces dataset as input from kaggle and import code for this dataset is provided below\n",
    "3. Do not exceed 8 epochs as this will increase the runtime beyond what is reasonable for extra credit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5wBmS6lsfIx"
   },
   "source": [
    "### Discriminator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboardX in /Users/ankita/Library/Python/3.9/lib/python/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: packaging in /Users/ankita/Library/Python/3.9/lib/python/site-packages (from tensorboardX) (24.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/ankita/Library/Python/3.9/lib/python/site-packages (from tensorboardX) (5.29.0)\n",
      "Requirement already satisfied: numpy in /Users/ankita/Library/Python/3.9/lib/python/site-packages (from tensorboardX) (1.24.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvkfydqwsfIx"
   },
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T13:13:43.961108Z",
     "iopub.status.busy": "2024-08-29T13:13:43.960792Z",
     "iopub.status.idle": "2024-08-29T13:13:45.559684Z",
     "shell.execute_reply": "2024-08-29T13:13:45.55869Z",
     "shell.execute_reply.started": "2024-08-29T13:13:43.96108Z"
    },
    "id": "c6xFrqMksfIx",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T13:13:40.120791Z",
     "iopub.status.busy": "2024-08-29T13:13:40.119885Z",
     "iopub.status.idle": "2024-08-29T13:13:43.943299Z",
     "shell.execute_reply": "2024-08-29T13:13:43.942459Z",
     "shell.execute_reply.started": "2024-08-29T13:13:40.120751Z"
    },
    "id": "8S-W98IFsfIx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, feature_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # Input: img_channels x 64 x 64\n",
    "            nn.Conv2d(channels_img, feature_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #, inplace=True\n",
    "            # Output: feature_d x 32 x 32\n",
    "            nn.Conv2d(feature_d, feature_d * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_d * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Output: (feature_d*2) x 16 x 16\n",
    "            nn.Conv2d(feature_d * 2, feature_d * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_d * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Output: (feature_d*4) x 8 x 8\n",
    "            nn.Conv2d(feature_d * 4, feature_d * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_d * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Output: (feature_d*8) x 4 x 4\n",
    "            nn.Conv2d(feature_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            \n",
    "            # Output: 1 x 1 x 1\n",
    "            nn.Sigmoid(),  \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDVZ1Jc9sfIx"
   },
   "source": [
    "### Generator Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T13:13:43.946244Z",
     "iopub.status.busy": "2024-08-29T13:13:43.945785Z",
     "iopub.status.idle": "2024-08-29T13:13:43.959239Z",
     "shell.execute_reply": "2024-08-29T13:13:43.957946Z",
     "shell.execute_reply.started": "2024-08-29T13:13:43.94621Z"
    },
    "id": "n-kJbHX_sfIx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            nn.ConvTranspose2d(channels_noise, features_g * 16, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 16),\n",
    "            nn.ReLU(),\n",
    "            # Output: N x (features_g * 16) x 4 x 4\n",
    "            nn.ConvTranspose2d(features_g * 16, features_g * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(),\n",
    "            # Output: N x (features_g * 8) x 8 x 8\n",
    "            nn.ConvTranspose2d(features_g * 8, features_g * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(),\n",
    "            # Output: N x (features_g * 4) x 16 x 16\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(),\n",
    "            # Output: N x (features_g * 2) x 32 x 32\n",
    "            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            # Output: N x channels_img x 64 x 64\n",
    "            nn.Tanh(),   #[-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights(model):\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                init.normal_(m.weight.data, 0.0, 0.02)\n",
    "def test():\n",
    "    N, channels_img, H, W = 8, 3, 64, 64\n",
    "    channels_noise = 100\n",
    "    x = torch.randn((N, channels_img, H, W))\n",
    "    discriminator = Discriminator(channels_img, 8)\n",
    "    initialize_weights(discriminator)\n",
    "    assert discriminator(x).shape == (N, 1, 1, 1)\n",
    "    generator = Generator(channels_noise, channels_img, 8)\n",
    "    initialize_weights(generator)\n",
    "    noise = torch.randn((N, channels_noise, 1, 1))\n",
    "    assert generator(noise).shape == (N, channels_img, H, W)\n",
    "    print(\"Success\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIjN0jlSsfIy"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T13:13:45.563236Z",
     "iopub.status.busy": "2024-08-29T13:13:45.562234Z",
     "iopub.status.idle": "2024-08-29T13:13:45.599562Z",
     "shell.execute_reply": "2024-08-29T13:13:45.598594Z",
     "shell.execute_reply.started": "2024-08-29T13:13:45.5632Z"
    },
    "id": "BqWeXga7sfIy",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remember to specify CPU instead of GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4\n",
    "batch_size = 128\n",
    "IMAGE_SIZE = 64\n",
    "channels_img = 3\n",
    "channels_noise = 100\n",
    "NUM_EPOCHS = 5 #Do not exceed 10 for your final submission\n",
    "features_d = 64\n",
    "features_g = 64\n",
    "\n",
    "generator = Generator(channels_noise, channels_img, features_g).to(device)\n",
    "discriminator = Discriminator(channels_img, features_d).to(device)\n",
    "\n",
    "initialize_weights(generator)\n",
    "initialize_weights(discriminator)\n",
    "\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# real_label = 1\n",
    "# fake_label = 0\n",
    "\n",
    "fix_noise = torch.randn(32, channels_noise, 1, 1).to(device)\n",
    "\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7aBGoUlsfIy"
   },
   "source": [
    "### Data-Loading and Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-29T13:13:45.601009Z",
     "iopub.status.busy": "2024-08-29T13:13:45.600719Z",
     "iopub.status.idle": "2024-08-29T13:16:28.384102Z",
     "shell.execute_reply": "2024-08-29T13:16:28.383078Z",
     "shell.execute_reply.started": "2024-08-29T13:13:45.600984Z"
    },
    "id": "IlCVWpQxsfIy",
    "outputId": "bf8dc3b7-b722-413e-9986-40b6ee9a4a64",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Specify the path to the destination directory\n",
    "# destination_path = \"/content/drive/MyDrive/CSS581-ML-Aut24/InputDataSets/img_align_celeba/img_align_celeba\"\n",
    "destination_path = \"img_align_celeba\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),   # Resize images to (64, 64)\n",
    "    transforms.ToTensor(),            # Convert image to tensor with range [0, 1]\n",
    "    transforms.Normalize(\n",
    "        [0.5 for _ in range(channels_img)], [0.5 for _ in range(channels_img)]),\n",
    "])\n",
    "\n",
    "# Update the root path to the extracted directory\n",
    "dataset = datasets.ImageFolder(root=destination_path, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfO66vFcsfIy"
   },
   "source": [
    "### Define Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T13:16:28.385648Z",
     "iopub.status.busy": "2024-08-29T13:16:28.38532Z",
     "iopub.status.idle": "2024-08-29T13:16:28.391707Z",
     "shell.execute_reply": "2024-08-29T13:16:28.390642Z",
     "shell.execute_reply.started": "2024-08-29T13:16:28.385622Z"
    },
    "id": "I0gZcbqesfIy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsDF4EsFsfIy"
   },
   "source": [
    "### Define Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Prl4Bsh-sfIy"
   },
   "source": [
    "#### Seed the randomizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7yvKuLS25J3",
    "outputId": "e1f69649-3d7b-49d3-9bf4-8cc2af7ee2dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [0/5] Batch 0/1067             Loss D: 1.3914, Loss G: 0.7854\n",
      "Epoch [0/5] Batch 100/1067             Loss D: 0.6445, Loss G: 2.8374\n",
      "Epoch [0/5] Batch 200/1067             Loss D: 1.0668, Loss G: 2.4847\n",
      "Epoch [0/5] Batch 300/1067             Loss D: 1.2055, Loss G: 1.6619\n",
      "Epoch [0/5] Batch 400/1067             Loss D: 1.1973, Loss G: 1.5150\n",
      "Epoch [0/5] Batch 500/1067             Loss D: 1.2144, Loss G: 1.5027\n",
      "Epoch [0/5] Batch 600/1067             Loss D: 0.9066, Loss G: 1.8152\n",
      "Epoch [0/5] Batch 700/1067             Loss D: 1.2241, Loss G: 1.7322\n",
      "Epoch [0/5] Batch 800/1067             Loss D: 1.2608, Loss G: 1.5920\n",
      "Epoch [0/5] Batch 900/1067             Loss D: 0.9457, Loss G: 2.0122\n",
      "Epoch [0/5] Batch 1000/1067             Loss D: 0.8842, Loss G: 1.9341\n",
      "Epoch [1/5] Batch 0/1067             Loss D: 0.8333, Loss G: 1.9934\n",
      "Epoch [1/5] Batch 100/1067             Loss D: 0.9032, Loss G: 2.6097\n",
      "Epoch [1/5] Batch 200/1067             Loss D: 1.1496, Loss G: 1.5881\n",
      "Epoch [1/5] Batch 300/1067             Loss D: 1.2938, Loss G: 1.0715\n",
      "Epoch [1/5] Batch 400/1067             Loss D: 0.7817, Loss G: 2.2272\n",
      "Epoch [1/5] Batch 500/1067             Loss D: 1.4175, Loss G: 1.7748\n",
      "Epoch [1/5] Batch 600/1067             Loss D: 0.8215, Loss G: 2.3103\n",
      "Epoch [1/5] Batch 700/1067             Loss D: 0.9766, Loss G: 1.2981\n",
      "Epoch [1/5] Batch 800/1067             Loss D: 1.1250, Loss G: 3.2047\n",
      "Epoch [1/5] Batch 900/1067             Loss D: 0.9275, Loss G: 2.5775\n",
      "Epoch [1/5] Batch 1000/1067             Loss D: 1.0561, Loss G: 2.3037\n",
      "Epoch [2/5] Batch 0/1067             Loss D: 1.1173, Loss G: 1.2233\n",
      "Epoch [2/5] Batch 100/1067             Loss D: 1.6265, Loss G: 3.1305\n",
      "Epoch [2/5] Batch 200/1067             Loss D: 0.8757, Loss G: 1.6662\n",
      "Epoch [2/5] Batch 300/1067             Loss D: 0.7621, Loss G: 1.7807\n",
      "Epoch [2/5] Batch 400/1067             Loss D: 1.6343, Loss G: 4.3530\n",
      "Epoch [2/5] Batch 500/1067             Loss D: 0.9310, Loss G: 1.5456\n",
      "Epoch [2/5] Batch 600/1067             Loss D: 0.9185, Loss G: 2.8943\n",
      "Epoch [2/5] Batch 700/1067             Loss D: 1.2252, Loss G: 2.9166\n",
      "Epoch [2/5] Batch 800/1067             Loss D: 0.8783, Loss G: 1.3878\n",
      "Epoch [2/5] Batch 900/1067             Loss D: 1.2227, Loss G: 0.7016\n",
      "Epoch [2/5] Batch 1000/1067             Loss D: 0.9469, Loss G: 1.8489\n",
      "Epoch [3/5] Batch 0/1067             Loss D: 1.0807, Loss G: 1.6397\n",
      "Epoch [3/5] Batch 100/1067             Loss D: 1.0143, Loss G: 1.2940\n",
      "Epoch [3/5] Batch 200/1067             Loss D: 1.3688, Loss G: 2.6680\n",
      "Epoch [3/5] Batch 300/1067             Loss D: 1.1311, Loss G: 3.6810\n",
      "Epoch [3/5] Batch 400/1067             Loss D: 1.1808, Loss G: 2.1048\n",
      "Epoch [3/5] Batch 500/1067             Loss D: 0.9483, Loss G: 1.5155\n",
      "Epoch [3/5] Batch 600/1067             Loss D: 0.8835, Loss G: 1.5835\n",
      "Epoch [3/5] Batch 700/1067             Loss D: 0.8642, Loss G: 1.7819\n",
      "Epoch [3/5] Batch 800/1067             Loss D: 1.0814, Loss G: 1.7490\n",
      "Epoch [3/5] Batch 900/1067             Loss D: 0.9198, Loss G: 1.3760\n",
      "Epoch [3/5] Batch 1000/1067             Loss D: 0.9878, Loss G: 1.1465\n",
      "Epoch [4/5] Batch 0/1067             Loss D: 1.3378, Loss G: 0.7020\n",
      "Epoch [4/5] Batch 100/1067             Loss D: 1.1496, Loss G: 0.8307\n",
      "Epoch [4/5] Batch 200/1067             Loss D: 1.1705, Loss G: 0.9118\n",
      "Epoch [4/5] Batch 300/1067             Loss D: 0.9703, Loss G: 1.5193\n",
      "Epoch [4/5] Batch 400/1067             Loss D: 0.9704, Loss G: 1.2788\n",
      "Epoch [4/5] Batch 500/1067             Loss D: 0.9534, Loss G: 1.8373\n",
      "Epoch [4/5] Batch 600/1067             Loss D: 1.0518, Loss G: 1.1423\n",
      "Epoch [4/5] Batch 700/1067             Loss D: 0.9737, Loss G: 1.3204\n",
      "Epoch [4/5] Batch 800/1067             Loss D: 0.9389, Loss G: 1.3736\n",
      "Epoch [4/5] Batch 900/1067             Loss D: 1.0410, Loss G: 1.1042\n",
      "Epoch [4/5] Batch 1000/1067             Loss D: 1.0982, Loss G: 0.9494\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "        for batch_idx, (data, _) in enumerate(dataloader):\n",
    "          data = data.to(device)\n",
    "          noise = torch.randn(batch_size, channels_noise, 1, 1).to(device)\n",
    "          fake = generator(noise)\n",
    "          \n",
    "          ###Train discriminator: max log(D(x)) + log(1-D(G(z)))\n",
    "          disc_real = discriminator(data).reshape(-1)\n",
    "          lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "          disc_fake = discriminator(fake).reshape(-1)\n",
    "          lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake)) \n",
    "\n",
    "          lossD = (lossD_real + lossD_fake) \n",
    "          discriminator.zero_grad()\n",
    "          lossD.backward(retain_graph=True)\n",
    "          disc_optimizer.step()\n",
    "\n",
    "          ###Train generator: max log(D(G(z)))\n",
    "          output = discriminator(fake).reshape(-1)\n",
    "          lossG = criterion(output, torch.ones_like(output))\n",
    "          generator.zero_grad()\n",
    "          lossG.backward()\n",
    "          gen_optimizer.step()\n",
    "\n",
    "          if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "            Loss D: {lossD:.4f}, Loss G: {lossG:.4f}\")\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fix_noise)\n",
    "                img_grid_real = torchvision.utils.make_grid(data[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step = step)\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcOjVvD-sfIz"
   },
   "source": [
    "### Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T14:00:12.933876Z",
     "iopub.status.busy": "2024-08-29T14:00:12.933545Z",
     "iopub.status.idle": "2024-08-29T14:00:13.194883Z",
     "shell.execute_reply": "2024-08-29T14:00:13.193792Z",
     "shell.execute_reply.started": "2024-08-29T14:00:12.933837Z"
    },
    "id": "4tTazvcasfIz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "     filename = f'generated_images_epoch_{epoch_no}.png'\n",
    "     try:\n",
    "        # Load the image\n",
    "        img = Image.open(filename)\n",
    "\n",
    "        # Display the image using matplotlib\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(transforms.ToPILImage()(transforms.ToTensor()(img)))\n",
    "        plt.axis('off')  # Turn off axis for better visualization\n",
    "        plt.title(f'Generated Images - Epoch {epoch_no}')\n",
    "        plt.show()\n",
    "      except FileNotFoundError:\n",
    "        print(f\"No image found for epoch {epoch_no}. Ensure the file '{filename}' exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T14:00:13.197195Z",
     "iopub.status.busy": "2024-08-29T14:00:13.196376Z",
     "iopub.status.idle": "2024-08-29T14:00:13.965543Z",
     "shell.execute_reply": "2024-08-29T14:00:13.964549Z",
     "shell.execute_reply.started": "2024-08-29T14:00:13.197158Z"
    },
    "id": "I0kN_DpisfIz",
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T14:00:13.967297Z",
     "iopub.status.busy": "2024-08-29T14:00:13.966968Z",
     "iopub.status.idle": "2024-08-29T14:00:14.010496Z",
     "shell.execute_reply": "2024-08-29T14:00:14.009053Z",
     "shell.execute_reply.started": "2024-08-29T14:00:13.967271Z"
    },
    "id": "y0vOUnIosfIz",
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 29561,
     "sourceId": 37705,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
